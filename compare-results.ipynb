{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the results of logistic regression and boosted classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from helpers import format_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Train Shape: (18255, 1235)\n",
      "Test Shape: (27285, 1234)\n",
      "\n",
      "Converting to dummy variables...\n",
      "\n",
      "Splitting into train and validation set...\n",
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "seed = 37\n",
    "\n",
    "print 'Loading data...\\n'\n",
    "train = pd.read_csv('data/train.csv', low_memory=False)\n",
    "test = pd.read_csv('data/test.csv', low_memory=False)\n",
    "\n",
    "print 'Train Shape: {}'.format(train.shape)\n",
    "print 'Test Shape: {}\\n'.format(test.shape)\n",
    "\n",
    "label = train['is_female']\n",
    "del train['is_female']\n",
    "\n",
    "del train['train_id']\n",
    "del test['test_id']\n",
    "\n",
    "# Remove rows/columns that are missing all data\n",
    "train = train.dropna(axis=0, how='all')\n",
    "train = train.dropna(axis=1, how='all')\n",
    "\n",
    "# Convert to dummy variables\n",
    "print 'Converting to dummy variables...\\n'\n",
    "train_str = train.applymap(str)\n",
    "train_dummies = pd.get_dummies(train_str)\n",
    "\n",
    "# Split into train and validation set\n",
    "print 'Splitting into train and validation set...\\n'\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dummies, label, test_size=0.2, random_state=seed)\n",
    "\n",
    "print 'Complete.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(trainX, trainY, testX, testY):\n",
    "    print 'Fitting logistic regression...\\n'\n",
    "    clf = LogisticRegression(C=0.2, penalty='l1', solver='liblinear')\n",
    "    clf.fit(trainX, trainY)\n",
    "    preds = clf.predict_proba(testX)\n",
    "    #score = roc_auc_score(testY, preds)\n",
    "    #return [score, preds]\n",
    "    return preds\n",
    "\n",
    "def xgb_clf(trainX, trainY, testX, testY, seed):\n",
    "    print 'Fitting XGB Classifier...\\n'\n",
    "    clf = XGBClassifier(max_depth=7, n_estimators=100, random_state=seed)\n",
    "    clf.fit(trainX, trainY, eval_metric='auc')\n",
    "    preds = clf.predict_proba(testX)\n",
    "    #score = roc_auc_score(testY, preds)\n",
    "    #return [score, preds]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting XGB Classifier...\n",
      "\n",
      "XGBoost Classifier with SelectKBest, 1003 Features\n",
      "Run time: 1.87 minutes\n",
      "\n",
      "Fitting logistic regression...\n",
      "\n",
      "Logistic Regression with VarianceThreshold, 0 Features\n",
      "Run time: 0.05 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB with SelectKBest (k=1003)\n",
    "k=1003\n",
    "ch2 = SelectKBest(chi2, k=k)\n",
    "X_train_new = ch2.fit_transform(X_train, y_train)\n",
    "X_test_new = ch2.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "results = xgb_clf(X_train_new, y_train, X_test_new, y_test, seed)\n",
    "end = time.time()\n",
    "run_time = float(end - start)/60\n",
    "\n",
    "#score_xgb = results[0]\n",
    "prediction_xgb = results\n",
    "\n",
    "print 'XGBoost Classifier with SelectKBest, {} Features'.format(k)\n",
    "#print 'ROC AUC Score: {}'.format(score)\n",
    "print 'Run time: {:0.2f} minutes\\n'.format(run_time)\n",
    "\n",
    "# Logistic Regression with Variance Threshold (t=0)\n",
    "t=0\n",
    "sel = VarianceThreshold(threshold=t)\n",
    "X_train_new = sel.fit_transform(X_train)\n",
    "X_test_new = sel.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "results = log_reg(X_train_new, y_train, X_test_new, y_test)\n",
    "end = time.time()\n",
    "run_time = float(end - start)/60\n",
    "\n",
    "#score_logreg = results[0]\n",
    "prediction_logreg = results\n",
    "\n",
    "print 'Logistic Regression with VarianceThreshold, {} Features'.format(t)\n",
    "#print 'ROC AUC Score: {}'.format(score)\n",
    "print 'Run time: {:0.2f} minutes\\n'.format(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_female_xgb</th>\n",
       "      <th>is_female_logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_female_xgb  is_female_logreg\n",
       "0        0            1.0               1.0\n",
       "1        1            1.0               1.0\n",
       "2        2            0.8               0.8\n",
       "3        3            0.0               0.0\n",
       "4        4            1.0               1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb = format_submission(prediction_xgb)\n",
    "df_logreg = format_submission(prediction_logreg)\n",
    "df = df_xgb.merge(df_logreg, how='inner', on='test_id', suffixes=('_xgb', '_logreg'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1657, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagree = df[df.is_female_xgb != df.is_female_logreg]\n",
    "df_disagree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of labels on which the classifiers disagree: 45.38%\n"
     ]
    }
   ],
   "source": [
    "p = (float(len(df_disagree))/len(df))*100\n",
    "print 'Percentage of labels on which the classifiers disagree: {:.2f}%'.format(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>LogReg</th>\n",
       "      <th>TrueLabel</th>\n",
       "      <th>TestID</th>\n",
       "      <th>TestIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB  LogReg  TrueLabel  TestID  TestIndex\n",
       "0  1.0     1.0          1       0      18008\n",
       "1  1.0     1.0          1       1      11362\n",
       "2  0.8     0.8          1       2       2269\n",
       "3  0.0     0.0          0       3      10380\n",
       "4  1.0     1.0          1       4        240"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the true labels into the mix\n",
    "df_true = pd.DataFrame(y_test)\n",
    "df_true.columns = ['TrueLabel']\n",
    "df_true['test_id'] = range(len(df_true))\n",
    "df_true.head()\n",
    "df_true.reset_index(inplace=True)\n",
    "df_joined = df.merge(df_true, how='inner', on='test_id')\n",
    "df_joined.columns = ['TestID', 'XGB', 'LogReg', 'TestIndex', 'TrueLabel']\n",
    "df_joined = df_joined[['XGB', 'LogReg', 'TrueLabel', 'TestID', 'TestIndex']]\n",
    "df_joined.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
